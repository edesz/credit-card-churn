{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0ec243-5977-4e55-9a27-ad27ad445a82",
   "metadata": {},
   "source": [
    "# (All Data) Get At-Risk Customers Using Business Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7669f24-ce3e-444b-a556-ab011348e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from io import BytesIO, StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import botocore.exceptions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa48a3-f589-45a8-8c97-cc68d0298380",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d63c34-fc13-4991-a13d-ba93d3e15f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert load_dotenv(dotenv_path=PROJ_ROOT.parent / '.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d5022-cf30-4c71-a0ba-e4cc37708dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cc_churn.costs as costs\n",
    "import cc_churn.visualization as vzu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2c67f-08e4-4721-abd8-730f6bcd498c",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9546ecec-c661-43e9-ba91-40e716039a74",
   "metadata": {},
   "source": [
    "Get the at-risk customers and predicted ROI using all available data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9032175-6c5b-4d3d-acce-a891c3752de5",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9db5e8-5055-42ae-96f8-fb05b4111cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 data bucket details\n",
    "bucket_name = 'cc-churn-splits'\n",
    "# # name of validation data with predictions key (file) in private R2 bucket\n",
    "r2_key_all_partial = 'all_predictions__logisticregression__'\n",
    "# # name of validation data with predictions key (file) in private R2 bucket\n",
    "r2_key_val_partial = 'validation_predictions__logisticregression__'\n",
    "\n",
    "# columns to load\n",
    "columns = [\n",
    "    'clientnum',\n",
    "    'card_category',\n",
    "    'total_revolv_bal',\n",
    "    'total_trans_amt',\n",
    "    'model_name',\n",
    "    'y_pred_proba',\n",
    "    'y_pred',\n",
    "    'best_decision_threshold',\n",
    "    'is_churned',\n",
    "]\n",
    "\n",
    "# costs\n",
    "# # revenue from transactions (bank earns #% of transaction volume)\n",
    "interchange_rate = 0.02\n",
    "# # revenue from revolving balance (~20% interest)\n",
    "apr = 0.18\n",
    "# # fee revenue from credit card exposure (modeled from card type)\n",
    "card_fees = {\"Blue\": 0, \"Silver\": 50, \"Gold\": 100, \"Platinum\": 200}\n",
    "tenure_years = 3\n",
    "discount = 0.9\n",
    "# # percentage of churners who can be convinced to stay (i.e. success rate\n",
    "# # of saving a churning customer)\n",
    "success_rate = 0.40\n",
    "# # cost of intervention to get a single customer to not churn (discounts,\n",
    "# # call center time, retention offers, etc.)\n",
    "intervention_cost = 50\n",
    "# # maximum number of customers that can be targeted based on client's budget\n",
    "num_customers_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dff478-e44b-47dc-bf9f-96d8d9b0fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = os.getenv('ACCOUNT_ID')\n",
    "access_key_id = os.getenv('ACCESS_KEY_ID')\n",
    "secret_access_key = os.getenv('SECRET_ACCESS_KEY')\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=f'https://{account_id}.r2.cloudflarestorage.com',\n",
    "    aws_access_key_id=access_key_id,\n",
    "    aws_secret_access_key=secret_access_key,\n",
    "    region_name='auto'\n",
    ")\n",
    "\n",
    "# costs\n",
    "multiplier = (1 - discount**tenure_years) / (1 - discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b34726-829f-447a-bd68-c175df46f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_read_parquet_r2(bucket_name, r2_key, columns):\n",
    "    \"\"\"Read parquet file from private R2 bucket.\"\"\"\n",
    "    s3_object = s3_client.get_object(Bucket=bucket_name, Key=r2_key)\n",
    "    df = pd.read_parquet(\n",
    "        BytesIO(s3_object['Body'].read()),\n",
    "        columns=columns,\n",
    "        dtype_backend='pyarrow',\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def pandas_read_filtered_parquets_r2(bucket_name, key_prefix, cols_to_load):\n",
    "    \"\"\"Read parquet files using partial filename from private R2 bucket.\"\"\"\n",
    "    s3_objects = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name, Prefix=key_prefix, MaxKeys=1\n",
    "    )\n",
    "    assert s3_objects['ResponseMetadata']['HTTPStatusCode'] == 200\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            pandas_read_parquet_r2(\n",
    "                bucket_name, obj['Key'], columns=cols_to_load\n",
    "            )\n",
    "            for obj in s3_objects['Contents']\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def export_df_to_r2(df, bucket_name, r2_key):\n",
    "    \"\"\"Export DataFrame to file in private R2 bucket, if not present.\"\"\"\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=r2_key)\n",
    "        print(f\"Key {r2_key} already exists in bucket {bucket_name}\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "            print(f\"Key {r2_key} does not exist in bucket {bucket_name}\")\n",
    "            buffer = BytesIO()\n",
    "            df.to_parquet(\n",
    "                buffer,\n",
    "                index=False,\n",
    "                engine='pyarrow',\n",
    "                compression='gzip',\n",
    "            )\n",
    "            response = s3_client.put_object(\n",
    "                Bucket=bucket_name, Key=r2_key, Body=buffer.getvalue()\n",
    "            )\n",
    "            assert response['ResponseMetadata']['HTTPStatusCode'] == 200\n",
    "            print(f\"Exported {len(df):,} rows to key: {r2_key}\")\n",
    "        elif e.response[\"Error\"][\"Code\"] == \"403\":\n",
    "            print(f\"Access denied to bucket {bucket_name} or key {r2_key}\")\n",
    "        else:\n",
    "            print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf91534-0391-43d9-abce-ef72c98ddbbe",
   "metadata": {},
   "source": [
    "## Load Data with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37717c72-e2bf-4b84-8cd7-be6da16deb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble as skens\n",
    "import sklearn.metrics as mtr\n",
    "import sklearn.preprocessing as pp\n",
    "import sklearn.utils as skut\n",
    "from IPython.display import display\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# R2 data bucket details\n",
    "bucket_name = \"cc-churn-splits\"\n",
    "\n",
    "# columns to load\n",
    "columns = [\n",
    "    \"clientnum\",\n",
    "    \"card_category\",\n",
    "    \"total_revolv_bal\",\n",
    "    \"total_trans_amt\",\n",
    "    \"model_name\",\n",
    "    \"y_pred_proba\",\n",
    "    \"y_pred\",\n",
    "    \"best_decision_threshold\",\n",
    "    \"is_churned\",\n",
    "]\n",
    "\n",
    "ordinal_features = [\n",
    "    \"income_category\",\n",
    "    \"education_level\",\n",
    "]\n",
    "categorical_features = [\n",
    "    # 'card_category',\n",
    "    \"marital_status\",\n",
    "]\n",
    "numeric_features = [\n",
    "    # 'customer_age',\n",
    "    # # 'dependent_count',\n",
    "    \"months_on_book\",\n",
    "    \"num_products\",\n",
    "    \"months_inactive_12_mon\",\n",
    "    \"contacts_count_12_mon\",\n",
    "    \"total_revolv_bal\",\n",
    "    # 'avg_open_to_buy',\n",
    "    \"total_amt_chng_q4_q1\",\n",
    "    # 'total_trans_amt',\n",
    "    \"total_trans_ct\",\n",
    "    \"total_ct_chng_q4_q1\",\n",
    "    # 'avg_utilization_ratio',\n",
    "]\n",
    "features = numeric_features + ordinal_features + categorical_features\n",
    "\n",
    "\n",
    "def pandas_read_parquet_r2_c(s3_client, bucket_name, r2_key, columns):\n",
    "    \"\"\"Read parquet file from private R2 bucket.\"\"\"\n",
    "    s3_object = s3_client.get_object(Bucket=bucket_name, Key=r2_key)\n",
    "    df = pd.read_parquet(\n",
    "        BytesIO(s3_object[\"Body\"].read()),\n",
    "        columns=columns,\n",
    "        dtype_backend=\"pyarrow\",\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = pandas_read_parquet_r2_c(\n",
    "    s3_client, bucket_name, \"train_data.parquet.gzip\", None\n",
    ")\n",
    "df_val = pandas_read_parquet_r2_c(\n",
    "    s3_client, bucket_name, \"validation_data.parquet.gzip\", None\n",
    ")\n",
    "df_test = pandas_read_parquet_r2_c(\n",
    "    s3_client, bucket_name, \"test_data.parquet.gzip\", None\n",
    ")\n",
    "\n",
    "df = pd.concat([df_train, df_val, df_test])\n",
    "X = df.drop(columns=[\"is_churned\"])\n",
    "y = df[\"is_churned\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", pp.MinMaxScaler())])\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"ohe\", pp.OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\"))]\n",
    ")\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"oe\",\n",
    "            pp.OrdinalEncoder(\n",
    "                categories=[\n",
    "                    [\n",
    "                        \"Unknown\",\n",
    "                        \"Less than $40K\",\n",
    "                        \"$40K - $60K\",\n",
    "                        \"$60K - $80K\",\n",
    "                        \"$80K - $120K\",\n",
    "                        \"$120K +\",\n",
    "                    ],\n",
    "                    [\n",
    "                        \"Unknown\",\n",
    "                        \"Uneducated\",\n",
    "                        \"High School\",\n",
    "                        \"College\",\n",
    "                        \"Graduate\",\n",
    "                        \"Post-Graduate\",\n",
    "                        \"Doctorate\",\n",
    "                    ],\n",
    "                ],\n",
    "                handle_unknown=\"use_encoded_value\",\n",
    "                dtype=np.float64,\n",
    "                unknown_value=np.nan,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"ord\", ordinal_transformer, ordinal_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# clf = LogisticRegression(\n",
    "#     class_weight='balanced', random_state=42, n_jobs=-1\n",
    "# )\n",
    "clf = skens.HistGradientBoostingClassifier(\n",
    "    # # VERSION 1\n",
    "    # max_depth=3,\n",
    "    # max_bins=255,\n",
    "    # l2_regularization=0.25,\n",
    "    # learning_rate=0.1,\n",
    "    # max_iter=250,\n",
    "    # class_weight='balanced',\n",
    "    # random_state=42,\n",
    "    # VERSION 2\n",
    "    max_depth=3,\n",
    "    l2_regularization=0.25,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    ")\n",
    "# clf = skens.RandomForestClassifier(\n",
    "#     n_estimators=600,\n",
    "#     max_depth=3,\n",
    "#     class_weight='balanced',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "pipe = Pipeline([(\"pre\", preprocessor), (\"clf\", clf)])\n",
    "\n",
    "best_decision_threshold = 0.5\n",
    "\n",
    "pipe.fit(X, y)\n",
    "y_pred_proba = pipe.predict_proba(X)[:, 1]\n",
    "y_pred_proba = pd.Series(y_pred_proba, name=\"y_pred_proba\", index=X.index)\n",
    "y_pred = (y_pred_proba >= best_decision_threshold).astype(int).rename('y_pred')\n",
    "\n",
    "df_all_pred = (\n",
    "    pd.concat([df, y_pred_proba, y_pred], axis=1)\n",
    "    .assign(\n",
    "        model_name=type(clf).__name__,\n",
    "        best_decision_threshold=best_decision_threshold,\n",
    "    )[columns]\n",
    ")\n",
    "assert df_all_pred.isna().sum().sum() == 0\n",
    "\n",
    "print(\n",
    "    f\"Size of all data = {len(df_all_pred):,} rows X {df_all_pred.shape[1]:,} \"\n",
    "    \"columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e0104-ff5e-4017-9eac-7e35672064a8",
   "metadata": {},
   "source": [
    "Load all available data with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8e71d-bcdc-4961-a7cc-15a7002f481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# df_all_pred = pandas_read_filtered_parquets_r2(bucket_name, r2_key_all_partial, columns)\n",
    "print(f\"Got {len(df_all_pred):,} rows of all available data\")\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f1918-1df9-4493-9bc3-c7ece95b2922",
   "metadata": {},
   "source": [
    "Extract best decision threshold and name of best ML model from model predictions of the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdfc624-69c2-49f4-b446-f1f348a5e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_decision_threshold, best_model_name = pandas_read_filtered_parquets_r2(\n",
    "    bucket_name, r2_key_val_partial, ['best_decision_threshold', 'model_name']\n",
    ").head(1).squeeze().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc15f9-9dd1-452e-b2c2-9c8b41a0e163",
   "metadata": {},
   "source": [
    "## All Available Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccea34-3d8c-4462-bc01-5046e022ebb1",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc2622-011e-43cb-8625-1cbccb9d4047",
   "metadata": {},
   "source": [
    "Get the true and predicted class imbalance for all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb7f2a-b1c5-405b-9119-ae465b2aaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_true_pred_class_imbalance = (\n",
    "    (\n",
    "        df_all_pred['y_pred']\n",
    "        .value_counts(normalize=True)\n",
    "        .rename('predicted')\n",
    "        .to_frame()\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            df_all_pred['is_churned']\n",
    "            .value_counts(normalize=True)\n",
    "            .rename('true')\n",
    "            .to_frame()\n",
    "        ),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    ")\n",
    "df_true_pred_class_imbalance.index = df_true_pred_class_imbalance.index.map(\n",
    "    {0: 'No Churn', 1: 'Churn'}\n",
    ")\n",
    "churn_true = (df_true_pred_class_imbalance.loc['Churn'].mul(100))['true']\n",
    "churn_pred = (df_true_pred_class_imbalance.loc['Churn'].mul(100))['predicted']\n",
    "df_true_pred_class_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31139367-5456-4f7e-a4c2-967b9fb24347",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\n",
    "    \"**Observations**\\n\"\n",
    "    f\"1. The class imbalance in the test split is approximately the same as that \"\n",
    "    f\"in the training split, which was seen in the EDA notebook. \"\n",
    "    f\"~{100*churn_true:.2f}% of customers showed churn in the test data.\\n\"\n",
    "    f\"2. Due to the inaccuracy of the model, ~{churn_pred:.2f}% instead of \"\n",
    "    f\"~{churn_true:.2f}% of customers are predicted to churn.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc730fc-92e0-4fdd-bb2a-e8232461f47e",
   "metadata": {},
   "source": [
    "Show the class imbalance and distribution of prediction probabilities for all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60a2c8-f01b-4bbe-b7e3-876364c58182",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vzu.plot_class_imbalance_proba_distribution(\n",
    "    df_clasS_imbalance=df_true_pred_class_imbalance.rename(columns=str.title),\n",
    "    df_probabilities=(df_all_pred['y_pred_proba']*100),\n",
    "    ptitle1='~10% Higher Churn Predicted in Test Split',\n",
    "    title1_xloc=-0.3,\n",
    "    ptitle2=(\n",
    "        'Predicted Probabilities show Right Skew with Weak Peak Above ~90%'\n",
    "    ),\n",
    "    vline_label=f'Optimized Churn Cutoff ({best_decision_threshold*100:.0f}%)',\n",
    "    decision_threshold=best_decision_threshold,\n",
    "    subfigure_width_ratios=[1.15, 3],\n",
    "    fig_size=(12, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc4811-4d5a-48e2-b867-6cde339a578f",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. Similar to the test split, the distribution of predicted probabilities shows a right-skew."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257665a-c38e-4365-99ed-bf5f1063c989",
   "metadata": {},
   "source": [
    "### Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04204ace-1bf9-4bac-bc3e-0340c42150dd",
   "metadata": {},
   "source": [
    "Calculate the true savings, expected (predicted) savings and error in predicted savings (cost) using all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ad172-f34d-465a-8daf-15364a6e3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_costs_all, _, _ = costs.get_cost(\n",
    "    df_all_pred,\n",
    "    best_decision_threshold,\n",
    "    interchange_rate,\n",
    "    apr,\n",
    "    card_fees,\n",
    "    multiplier,\n",
    "    success_rate,\n",
    "    intervention_cost,\n",
    ")\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_costs_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c67570-4016-4e9b-875f-83e2225ae64a",
   "metadata": {},
   "source": [
    "### Get True and Predicted ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651514e-122d-4f85-9e6d-6273e4b240a8",
   "metadata": {},
   "source": [
    "Plot true and predicted expected savings and ROI curves to visualize the following\n",
    "\n",
    "1. true ROI\n",
    "2. predicted ROI\n",
    "\n",
    "using all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4848d8-6e39-4069-a480-95b59a08ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vzu.plot_roi_curves(\n",
    "    df_costs_all['n'],\n",
    "    df_costs_all['cum_true_savings'],\n",
    "    df_costs_all['cum_pred_savings'],\n",
    "    df_costs_all['ROI_percent'],\n",
    "    df_costs_all['ROI_percent_pred'],\n",
    "    {},\n",
    "    ptitle=(\n",
    "        'Excluding initial Noisy Period, ROI is Maximized after Selecting Top '\n",
    "        '74 At-Risk Customers'\n",
    "    ),\n",
    "    legend_loc='upper left',\n",
    "    xlabel=f\"Number of Predicted Churners to Contact (Top-N)\",\n",
    "    ylabel=\"Expected Net Savings ($)\",\n",
    "    fig_size=(12, 8),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cbff5c-373c-4df5-b94f-8675b99fb7bc",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. Customers with a high `total_revolv_bal` account for the sharp increase in ROI, resulting in a peak at ~500 customers. Between ~500 and ~900 customers, there are minimal such customers so further sharp increases are not seen. As mentioned in the previous notebook, selecting as many high total_revolv_bal customers as possible captures steep increases in ROI. Between ~900 and ~1,400, the high `total_revolv_bal` customers appear again. After selecting the top ~1,400 customers, ROI shows a weak downward trend.\n",
    "2. If the budget allows for targeting at most the top 1,000 customers (~10% of all customers in the random sample) then the optimal number of customers is ~500.\n",
    "3. If there is room in the budget to target all possible at-risk cutomers then the optimal number of customers is ~1,400. Here, we will assume this is true. So, the optimal number customers to be targeted is ~1,400."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b70e9c-ab66-4500-8786-46a5d8cee2a4",
   "metadata": {},
   "source": [
    "Find the optimal number of customers to target in order to maximize true ROI, using the costs on all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82accd-136d-450a-ad36-0acf9b7dfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_costs_optimal = (\n",
    "    df_costs_all\n",
    "    .query(\n",
    "        \"(total_intervention_cost > 0) & \"\n",
    "        # capture second peak in ROI\n",
    "        \"(n >= 750)\"\n",
    "    )\n",
    "    .sort_values(\n",
    "        by=['ROI', 'ROI_error', 'n'], ascending=[False, True, True],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    .head(1)\n",
    ")\n",
    "optimal_N_roi = df_costs_optimal['n'].squeeze()\n",
    "cols_costs = [\n",
    "    'n',\n",
    "    'cum_true_savings',\n",
    "    'cum_pred_savings',\n",
    "    'ROI_error',\n",
    "    'ROI_percent',\n",
    "    'ROI_percent_pred',\n",
    "]\n",
    "(\n",
    "    df_costs_optimal[cols_costs]\n",
    "    .style\n",
    "    .set_properties(\n",
    "        subset=['ROI_error', 'ROI_percent_pred'],\n",
    "        **{'background-color': 'yellow', 'color': 'black'}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22caafca-4ec3-4832-a4f0-d0cc3970eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_error_optimal_val = df_costs_optimal['ROI_error'].squeeze()\n",
    "predicted_roi_optimal_val = df_costs_optimal['ROI_percent_pred'].squeeze()\n",
    "Markdown(\n",
    "    \"**Observations**\\n\"\n",
    "    \"1. In order to minimize the error in predicted ROI while also maximizing \"\n",
    "    f\"true ROI, the optimal number of customers to target is {optimal_N_roi:,}. \"\n",
    "    \"This is consistent with observations from the chart above.\\n\"\n",
    "    f\"2. If the top {optimal_N_roi:,} customers from the test data are \"\n",
    "    \"targeted, then the\\n\"\n",
    "    \"   - error in the predicted ROI is approximately \"\n",
    "    f\"{roi_error_optimal_val:.1f}%\\n\"\n",
    "    f\"   - predicted ROI is approximately {predicted_roi_optimal_val:.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508da65-d9e4-488e-ade6-aad2c1d5cdcf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcf9c2-400b-4869-aa22-d6ef7cacc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_costs_all_true_pred = (\n",
    "    df_costs_all\n",
    "    .query(f\"n == {optimal_N_roi}\")\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"ROI_percent\": \"ROI_true_percent\",\n",
    "            'ROI_percent_pred': 'ROI_pred_percent',\n",
    "        }\n",
    "    )\n",
    "    .melt(\n",
    "        id_vars=['n', 'y_pred_proba'],\n",
    "        value_vars=[\n",
    "            'cum_true_savings',\n",
    "            'cum_pred_savings',\n",
    "            'ROI_true_percent',\n",
    "            'ROI_pred_percent',\n",
    "        ],\n",
    "        var_name='variable',\n",
    "        value_name='value',\n",
    "    )\n",
    "    .assign(metric=lambda df: df['variable'].str.split('_', expand=True)[2])\n",
    "    .pivot(\n",
    "        index=['n', 'y_pred_proba'], columns=['variable'], values='value'\n",
    "    )\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        pct_pred_error=lambda df: 100*(\n",
    "            (df['ROI_pred_percent']-df['ROI_true_percent'])\n",
    "            /df['ROI_true_percent']\n",
    "        )\n",
    "    )\n",
    ")\n",
    "error_pred_roi = df_costs_all_true_pred['pct_pred_error'].squeeze()\n",
    "display(\n",
    "    df_costs_all_true_pred\n",
    "    .style\n",
    "    .apply(\n",
    "        lambda x: [\n",
    "            'background: yellow' if x.name == 'pct_pred_error' else ''\n",
    "            for i in x\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31118159-e2a4-488e-9fb1-97b39bc62713",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\n",
    "    \"**Observations**\\n\"\n",
    "    \"1. If we apply the recommendations from predicted ROI and contact \"\n",
    "    f\"(target) the top {optimal_N_roi} customers, then the client is \"\n",
    "    f\"incorrectly reported a gain of approximately {error_pred_roi:.2f}% \"\n",
    "    \"of the maximum possible true ROI.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118ec1a-bb88-4656-8cbe-c044629c8ae8",
   "metadata": {},
   "source": [
    "Append column to costs indicating if targeting customer maximizes ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bc185-cb23-4c41-af48-40f0209f570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_costs_all = (\n",
    "    df_costs_all\n",
    "    .assign(maximizes_roi=lambda df: df['n'] <= optimal_N_roi)\n",
    ")\n",
    "(\n",
    "    df_costs_all\n",
    "    [\n",
    "        [\n",
    "            'clientnum',\n",
    "            'n',\n",
    "            'y_pred_proba',\n",
    "            'y_pred',\n",
    "            'clv',\n",
    "            'ROI_percent_pred',\n",
    "            'maximizes_roi',\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0636c950-85e9-41b5-bd67-e7b9b64067ff",
   "metadata": {},
   "source": [
    "### At-Risk Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b899b45-5b4d-471d-9f85-f1198587b0be",
   "metadata": {},
   "source": [
    "As mentioned in the previous notebook, the `y_pred` column indicates if a customer is at-risk (1) or not (0), so it will now be renamed to `is_at_risk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4aa59-7c1a-428d-a0c4-5059cc6f1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_costs_all = df_costs_all.rename(columns={'y_pred': 'is_at_risk'})\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_costs_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b799c-d4ba-4707-bebf-53bb4ef9b379",
   "metadata": {},
   "source": [
    "## Export Project Deliverables to Private R2 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797d3c2-2c47-43e4-8d11-51046569e7af",
   "metadata": {},
   "source": [
    "Get the current timestamp in the format `YYmmdd_HHMMSS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949547f-685a-4764-a016-d8d79a254eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720486e7-dbd1-4799-aff8-80abec61913f",
   "metadata": {},
   "source": [
    "### All Customers with Indicator of At-Risk and Maximizing ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e067bc07-05ea-4c26-b6dd-6c0fd41aabe5",
   "metadata": {},
   "source": [
    "Combine costs (predicted churners) with predicted non-churners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60664074-7583-4a1f-9a5a-1fd6bcc6f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_all_pred_with_costs = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            df_costs_all.assign(y_pred=1),\n",
    "            df_all_pred.query(\"y_pred != 1\"),\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    .fillna(\n",
    "        {\n",
    "            'interchange_rev': np.nan,\n",
    "            'interest_rev': np.nan,\n",
    "            'fee_rev': np.nan,\n",
    "            'annual_rev': np.nan,\n",
    "            'clv': np.nan,\n",
    "            'success_rate': np.nan,\n",
    "            'expected_savings': np.nan,\n",
    "            'true_savings': np.nan,\n",
    "            'cum_pred_savings': np.nan,\n",
    "            'cum_true_savings': np.nan,\n",
    "            'n': np.nan,\n",
    "            'random_savings': np.nan,\n",
    "            'total_intervention_cost': np.nan,\n",
    "            'ROI': np.nan,\n",
    "            'ROI_pred': np.nan,\n",
    "            'ROI_error': np.nan,\n",
    "            'ROI_percent': np.nan,\n",
    "            'ROI_percent_pred': np.nan,\n",
    "            'maximizes_roi': np.nan,\n",
    "            'is_at_risk': 0,\n",
    "        }\n",
    "    )\n",
    "    .convert_dtypes(dtype_backend='pyarrow')\n",
    ")\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df_all_pred_with_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87dbc39-7f49-4bb0-9420-4282bbdc225d",
   "metadata": {},
   "source": [
    "Next, export to a file in the R2 bucket with the following file name format `all_predictions_with_business_metrics__logisticregression__<current-timestamp-YYmmdd_HHMMSS>.parquet.gzip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64f46b-4623-469b-a009-07b43984d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# export_df_to_r2(\n",
    "#     df_all_pred_with_costs,\n",
    "#     bucket_name,\n",
    "#     (\n",
    "#         f\"all_predictions_with_business_metrics__{best_model_name.lower()}__\"\n",
    "#         f\"{curr_timestamp}.parquet.gzip\"\n",
    "#     ),\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
